{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lithium 0.25 (7/11/77).  LFTS wnl.  Urine tox neg.  Serum tox + fluoxetine 500; otherwise neg.  TSH 3.28.  BUN/Cr: 16/0.83.  Lipids unremarkable.  B12 363, Folate >20.  CBC: 4.9/36/308 Pertinent Medical Review of Systems Constitutional:\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df[72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 03/25/93\n",
      "1 6/18/85\n",
      "2 7/8/71\n",
      "3 9/27/75\n",
      "4 2/6/96\n",
      "5 7/06/79\n",
      "6 5/18/78\n",
      "7 10/24/89\n",
      "8 3/7/86\n",
      "9 4/10/71\n",
      "10 5/11/85\n",
      "11 4/09/75\n",
      "12 8/01/98\n",
      "13 1/26/72\n",
      "14 5/24/1990\n",
      "15 1/25/2011\n",
      "16 4/12/82\n",
      "17 10/13/1976\n",
      "18 4/24/98\n",
      "19 5/21/77\n",
      "    tahir_data\n",
      "0   1993-03-25\n",
      "1   1985-06-18\n",
      "2   1971-07-08\n",
      "3   1975-09-27\n",
      "4   1996-02-06\n",
      "5   1979-07-06\n",
      "6   1978-05-18\n",
      "7   1989-10-24\n",
      "8   1986-03-07\n",
      "9   1971-04-10\n",
      "10  1985-05-11\n",
      "11  1975-04-09\n",
      "12  1998-08-01\n",
      "13  1972-01-26\n",
      "14  1990-05-24\n",
      "15  2011-01-25\n",
      "16  1982-04-12\n",
      "17  1976-10-13\n",
      "18  1998-04-24\n",
      "19  1977-05-21\n",
      "20  1998-07-21\n",
      "21  1979-10-21\n",
      "22  1990-03-03\n",
      "23  1976-02-11\n",
      "24  1984-07-25\n",
      "25  1982-04-13\n",
      "26  1989-09-22\n",
      "27  1976-09-02\n",
      "28  1971-09-12\n",
      "29  1986-10-24\n",
      "..         ...\n",
      "470 1983-01-01\n",
      "471 1999-01-01\n",
      "472 2010-01-01\n",
      "473 1975-01-01\n",
      "474 1972-01-01\n",
      "475 2015-01-01\n",
      "476 1989-01-01\n",
      "477 1994-01-01\n",
      "478 1993-01-01\n",
      "479 1996-01-01\n",
      "480 2013-01-01\n",
      "481 1974-01-01\n",
      "482 1990-01-01\n",
      "483 1995-01-01\n",
      "484 2004-01-01\n",
      "485 1987-01-01\n",
      "486 1973-01-01\n",
      "487 1992-01-01\n",
      "488 1977-01-01\n",
      "489 1985-01-01\n",
      "490 2007-01-01\n",
      "491 2009-01-01\n",
      "492 1986-01-01\n",
      "493 1978-01-01\n",
      "494 2002-01-01\n",
      "495 1979-01-01\n",
      "496 2006-01-01\n",
      "497 2008-01-01\n",
      "498 2005-01-01\n",
      "499 1980-01-01\n",
      "\n",
      "[500 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "5      474\n",
       "6      153\n",
       "7       13\n",
       "8      129\n",
       "9       98\n",
       "10     111\n",
       "11     225\n",
       "12      31\n",
       "13     171\n",
       "14     191\n",
       "15     486\n",
       "16     335\n",
       "17     415\n",
       "18      36\n",
       "19     405\n",
       "20     323\n",
       "21     422\n",
       "22     375\n",
       "23     380\n",
       "24     345\n",
       "25      57\n",
       "26     481\n",
       "27     436\n",
       "28     104\n",
       "29     299\n",
       "      ... \n",
       "470    220\n",
       "471    208\n",
       "472    243\n",
       "473    139\n",
       "474    320\n",
       "475    383\n",
       "476    244\n",
       "477    198\n",
       "478    286\n",
       "479    480\n",
       "480    431\n",
       "481    279\n",
       "482    381\n",
       "483    463\n",
       "484    366\n",
       "485    439\n",
       "486    255\n",
       "487    401\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    231\n",
       "495    427\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Name: index, Length: 500, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import dateutil\n",
    "def date_sorter():\n",
    "    date_list = []\n",
    "    a = df.str.findall(r'\\d{1,2}\\-\\d{1,2}\\-\\d{2}|19\\d{2}|20\\d{2}|\\d{1,2}\\/\\d{4}|\\d{1,2}\\/+\\d+\\/+\\d{2,}|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\,?\\.?\\-?\\s?\\d*\\-?\\,?\\s?\\d{4}|\\d{2}\\s?[A-Za-z]{3,10}\\,?\\.?\\s?\\d{4}|\\w{3,}\\s?2\\d{1}\\w+\\,?\\s?\\d{4}|(?:January|February|March|April|May|June|July|August|September|October|November|December)\\,?\\s?\\d*\\s?\\d{4}|\\d{1,2}\\-\\d{1,2}\\-\\d{2}|19\\d{2}|20\\d{2}|\\d{1,2}\\/\\d{4}|\\d{1,2}\\/+\\d+\\/+\\d{2,}|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\.?\\-?\\s?\\d{2}\\-?\\,?\\s?\\d{4}|\\d{2}\\s?[A-Za-z]{3,10}\\,?\\.?\\s?\\d{4}|\\w{3,}\\s?2\\d{1}\\w+\\,?\\s?\\d{4}|(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{1,2}?\\s?\\d{4}|(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d*\\,?\\s?\\d{4}')\n",
    "    for i, cc in enumerate(a):\n",
    "        for b in cc:\n",
    "            if b:\n",
    "                if i < 20:\n",
    "                    print(i, b)\n",
    "                c = b.strip()\n",
    "                if len(c) == 4:\n",
    "                    c = '1/1/' + c\n",
    "                elif re.findall(r'^\\d{1,2}\\/+\\d{4}', c):\n",
    "                    d = c.split('/')\n",
    "                    c = d[0] + '/1/' + d[1]\n",
    "                elif re.findall(r'^[A-Za-z]+\\,?\\s\\d{4}', c):\n",
    "                    c = '1 ' + c\n",
    "                try:\n",
    "                    date_list.append(dateutil.parser.parse(c))\n",
    "                except:\n",
    "                    continue\n",
    "    df1 = pd.Series(date_list)\n",
    "    df2 = df1.to_frame()\n",
    "    df2.rename(columns={ df2.columns[0]: \"tahir_data\" }, inplace = True)\n",
    "    print(df2)\n",
    "    df2.sort_values(by = 'tahir_data', inplace=True)\n",
    "    df2.reset_index(inplace = True) \n",
    "    series = pd.Series(df2['index'], dtype=\"int32\")\n",
    "    return series\n",
    "date_sorter()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
